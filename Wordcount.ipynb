{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from random import randint\n",
    "import ssl\n",
    "#Step 1: Connect to MongoDB - Note: Change connection string as needed\n",
    "client = MongoClient(host=['mongodb+srv://Manpreet:Chahal123@cluster0.mzino.mongodb.net/test'],\n",
    "                     ssl_cert_reqs=ssl.CERT_NONE,\n",
    "                     document_class=dict, tz_aware=False, connect=True)\n",
    "db = client[\"ReuterDb\"]\n",
    "mycol = db[\"NewsData\"]\n",
    "\n",
    "count=''\n",
    "for x in mycol.find():\n",
    "    count=count+x['body']\n",
    "\n",
    "words=count.split()\n",
    "rdd=spark.sparkContext.parallelize(words)\n",
    "wordCounts = rdd.map(lambda word: (word, 1)).reduceByKey(lambda a,b:a +b) \n",
    "searchlist=['storm', 'winter', 'canada', 'hot', 'cold', 'flu', 'snow', 'indoor', 'safety', 'rain', 'ice']\n",
    "wordCounts=[(x.lower(),y) for x,y in wordCounts.collect()]\n",
    "searchdict={} \n",
    "for element in wordCounts:\n",
    "    if element[0] in searchlist:\n",
    "        if element[0] in searchdict:\n",
    "            searchdict[element[0]]+=element[1]\n",
    "            else:\n",
    "                searchdict[element[0]]=element[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from random import randint\n",
    "import ssl\n",
    "#Step 1: Connect to MongoDB - Note: Change connection string as needed\n",
    "client = MongoClient(host=['mongodb+srv://Manpreet:Chahal123@cluster0.mzino.mongodb.net/test'],\n",
    "                     ssl_cert_reqs=ssl.CERT_NONE,\n",
    "                     document_class=dict, tz_aware=False, connect=True)\n",
    "db = client[\"ProessedDb\"]\n",
    "mycol = db[\"A3TwitterProcessedData\"]\n",
    "count=''\n",
    "for x in mycol.find():\n",
    "    count=count+x['full_text']\n",
    "\n",
    "words=count.split()\n",
    "rdd=spark.sparkContext.parallelize(words)\n",
    "wordCounts = rdd.map(lambda word: (word, 1)).reduceByKey(lambda a,b:a +b) \n",
    "searchlist=['storm', 'winter', 'canada', 'hot', 'cold', 'flu', 'snow', 'indoor', 'safety', 'rain', 'ice']\n",
    "wordCounts=[(x.lower(),y) for x,y in wordCounts.collect()]\n",
    "searchdict={} \n",
    "for element in wordCounts:\n",
    "    if element[0] in searchlist:\n",
    "        if element[0] in searchdict:\n",
    "            searchdict[element[0]]+=element[1]\n",
    "            else:\n",
    "                searchdict[element[0]]=element[1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
